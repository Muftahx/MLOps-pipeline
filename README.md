````md
# ğŸ“ˆ Sales Quantity Classifier (MLOps Pipeline)

An end-to-end MLOps project that automates data processing, model training, tracking, and deployment. This system predicts sales quantity categories (e.g., `LOW`, `HIGH`) based on transaction data.

---

## ğŸš€ Key Features

- **Automated Pipeline:** Orchestrated using **Prefect** to handle Feature Engineering, Training, and Evaluation.
- **Model Registry:** Uses **MLflow** to track experiments, metrics, and manage model versions.
- **Real-time Serving:** Deploys the model as a REST API using **FastAPI**.
- **Containerization:** Fully Dockerized application with auto-training capabilities.
- **Robust Testing:** Includes automated health checks and integration tests.

---

## ğŸ“‚ Project Structure

```text
MLops2.0-main/
â”œâ”€â”€ configs/             # Configuration files for features and model parameters
â”œâ”€â”€ data/                # Raw and processed datasets
â”œâ”€â”€ pipelines/           # Prefect flows (Orchestration logic)
â”œâ”€â”€ src/                 # Source code (Training, Feature Eng., API)
â”œâ”€â”€ tests/               # Integration checks for the API
â”œâ”€â”€ Dockerfile           # Docker configuration
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ validate_pipeline.py # System health check script
â””â”€â”€ README.md            # Project documentation
````

---

## ğŸ³ Quick Start (Docker)

### 1ï¸âƒ£ Build the Image

We use `--no-cache` to ensure the model trains using the latest code and data.

```bash
docker build --no-cache -t sales-classifier:v1 .
```

### 2ï¸âƒ£ Run the Container

Starts the FastAPI server on port `8000`.

```bash
docker run -p 8000:8000 sales-classifier:v1
```

---

## âœ… Validation & Testing

This project includes tools to verify the integrity of the pipeline and API before deployment.

### ğŸ©º Pipeline Validator (`validate_pipeline.py`)

Runs a full **system health check**, validating:

* Required project files and directories
* Processed dataset schema
* Presence of a trained and registered MLflow model

```bash
python validate_pipeline.py
```

**Expected Output:**

```text
âœ… PASSED: All checks passed successfully!
```

---

### ğŸ§ª Automated Tests (`tests/`)

Uses **pytest** to run integration tests on the API logic, ensuring the prediction endpoint behaves correctly.

```bash
python -m pytest tests/
```

**Expected Output:**

```text
===== 2 passed in 1.05s =====
```

---

## âš¡ API Usage

### ğŸ” Using CURL (Terminal)

```bash
curl -X POST "http://127.0.0.1:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{
           "Date": "2025-04-26",
           "BranchID": "7",
           "InvoiceNumber": "INV-TEST",
           "ItemCode": "58842",
           "QuantitySold": 1
         }'
```

**Expected Response:**

```json
{
  "prediction": "LOW",
  "class_id": 0
}
```

---

## ğŸ”§ Troubleshooting

### â— Model Not Found / Path Errors

* The model is **trained inside the Docker image during build time**
* Do **NOT** mount a Windows-created `mlflow.db` into the container
* Always rebuild with:

```bash
docker build --no-cache -t sales-classifier:v1 .
```

